{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime,timedelta\n",
    "from code.utils import get_price_after\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############utils config###################\n",
    "time_file = '../data/input/time/NF_time.csv'\n",
    "time_column = 'time'\n",
    "price_folder = '../data/input/price/XAUUSD_NF_1min/'\n",
    "price_prefix = 'XAUUSD'\n",
    "price_column = 'price'\n",
    "service_fee = 4/100000.0\n",
    "\n",
    "args = {\n",
    "    \"time_file\" : time_file,\n",
    "    \"time_column\" : time_column,\n",
    "    \"price_folder\" : price_folder,\n",
    "    \"price_prefix\" : price_prefix,\n",
    "    \"price_column\" : price_column,\n",
    "    \"leverage\": 1,\n",
    "    \"point_base\":10.0,\n",
    "    \"service_fee\":service_fee,\n",
    "    \"skip_rows\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv(time_file)\n",
    "\n",
    "timefile_list = os.listdir('../data/input/price/XAUUSD_NF_1min')\n",
    "time_list = []\n",
    "for time in timefile_list:\n",
    "    time_list.append(datetime.strptime(time.replace('.csv','').replace('XAUUSD','').replace('.','/'),'%Y/%m/%d'))\n",
    "\n",
    "time_list.sort()\n",
    "\n",
    "data = []\n",
    "\n",
    "data_all = pd.read_csv(\"../data/input/x/NF.csv\")\n",
    "\n",
    "for item in data_all['date']:\n",
    "    time = datetime.strptime(item,'%Y/%m/%d')\n",
    "    if time in time_list:\n",
    "        data.append(list(data_all[data_all.date == item].iloc[0]))\n",
    "\n",
    "y_price = get_price_after(5,args = args,profit_point = 1000,loss_point = -1000, service_fee = service_fee,save_price = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造模型并验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [193.79661016949152, 191.0, 195.0, 4.967796610169491, 4.996610169491524, 5.022033898305083, 0.19661016949152546, 0.23559322033898317, 0.20677966101694917, 2.7966101694915255, -0.028813559322033857, -0.03898305084745764, -1.2033898305084745, -0.05423728813559318, -0.010169491525423726, -4.0, -0.025423728813559324, 0.028813559322033895]\n",
      "std: [72.19174173351011, 34.36116492746446, 76.02789869061452, 1.1652202215958565, 1.1976940634193571, 1.1923705447856685, 0.15082085936280926, 0.04829047119687413, 0.14247129992855187, 64.0500288462658, 0.11751866683363194, 0.13132868630160083, 106.54540551608403, 0.12774170314957245, 0.25168050028875716, 74.6250397100339, 0.05443509371017502, 0.15979604183267077]\n",
      "y_pred:  [ 1 -1 -1  1  1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1]\n",
      "y_test:  [ 1 -1  1  1  1 -1  1  1 -1  1 -1  1 -1 -1  1  1]\n",
      "训练数据集准确率： 0.9534883720930233\n",
      "测试集准确率： 0.8125\n",
      "                                            0\n",
      "NF_diff_bi UR_diff_bi HS_diff_bi y1 y_pred   \n",
      "0          0.0        0.0         1  1      4\n",
      "                      1.0         1  1      6\n",
      "           1.0        0.0         1  1      5\n",
      "                      1.0        -1 -1      1\n",
      "                                  1  1      6\n",
      "1          0.0        0.0        -1 -1      3\n",
      "                                  1  1      1\n",
      "                      1.0        -1 -1      3\n",
      "                                  1 -1      1\n",
      "                                     1      1\n",
      "           1.0        0.0        -1 -1      6\n",
      "                                  1 -1      1\n",
      "                      1.0        -1 -1      5\n",
      "                                            0\n",
      "NF_diff_bi UR_diff_bi HS_diff_bi y1 y_pred   \n",
      "0          0.0        0.0         1  1      1\n",
      "                      1.0         1  1      2\n",
      "           1.0        0.0         1  1      1\n",
      "                      1.0         1  1      3\n",
      "1          0.0        1.0        -1 -1      1\n",
      "           1.0        0.0        -1 -1      1\n",
      "                                  1 -1      3\n",
      "                      1.0        -1 -1      4\n",
      "0.8333333333333335\n",
      "coef: [[-1.03448822  0.23754841 -0.2418439   0.12376236  0.15298568  0.14432753\n",
      "  -0.32862321 -0.72987482 -0.69119416 -1.2934256  -0.3320293  -0.10901835\n",
      "  -0.52836275 -0.21826463  0.19434201  0.35576964  0.20461333  0.39568772\n",
      "  -1.0742329   0.36672291 -0.13393514]]\n",
      "intercept: [0.39621412]\n"
     ]
    }
   ],
   "source": [
    "df_diff = pd.DataFrame(data)\n",
    "df_diff.columns = data_all.columns\n",
    "df_diff['year'] = pd.to_datetime(df_diff['date']).dt.year\n",
    "df_diff['y1'] = list(y_price['signal'])\n",
    "\n",
    "df_diff['NF_diff'] = df_diff['NF_actual'] - df_diff['NF_forecast']\n",
    "df_diff['UR_diff'] = df_diff['UR_actual'] - df_diff['UR_forecast']\n",
    "df_diff['HS_diff'] = df_diff['HS_actual'] - df_diff['HS_forecast']\n",
    "\n",
    "df_diff['NF_diff_AP'] = df_diff['NF_actual'] - df_diff['previous']\n",
    "df_diff['UR_diff_AP'] = df_diff['UR_actual'] - df_diff['UR_previous']\n",
    "df_diff['HS_diff_AP'] = df_diff['HS_actual'] - df_diff['HS_previous']\n",
    "\n",
    "df_diff['NF_diff_FP'] = df_diff['NF_forecast'] - df_diff['previous']\n",
    "df_diff['UR_diff_FP'] = df_diff['UR_forecast'] - df_diff['UR_previous']\n",
    "df_diff['HS_diff_FP'] = df_diff['HS_forecast'] - df_diff['HS_previous']\n",
    "\n",
    "bi = preprocessing.Binarizer(copy=True, threshold=-0.000001)\n",
    "\n",
    "df_diff['NF_diff_bi'] = bi.transform(pd.DataFrame(df_diff['NF_diff']))\n",
    "df_diff['UR_diff_bi'] = bi.transform(pd.DataFrame(df_diff['UR_diff']))\n",
    "df_diff['HS_diff_bi'] = bi.transform(pd.DataFrame(df_diff['HS_diff']))\n",
    "\n",
    "#划分数据集\n",
    "\n",
    "#option1:随机打乱\n",
    "# shuffle(df_diff,random_state = 0)\n",
    "# percentage = 0.8\n",
    "# df_train = df_diff[:int(df_diff.shape[0]*percentage)]\n",
    "# df_test = df_diff[int(df_diff.shape[0]*percentage):]\n",
    "\n",
    "#option2:按年份划分\n",
    "df_train = df_diff[df_diff.year < 2018]\n",
    "df_test = df_diff[df_diff.year >= 2018]\n",
    "\n",
    "diff = ['NF_diff','UR_diff','HS_diff','NF_diff_AP','UR_diff_AP','HS_diff_AP','NF_diff_FP','UR_diff_FP','HS_diff_FP']\n",
    "\n",
    "diff_bi = ['NF_diff_bi','UR_diff_bi','HS_diff_bi']\n",
    "\n",
    "origin = ['NF_actual', 'NF_forecast', 'previous',\n",
    "       'UR_actual', 'UR_forecast', 'UR_previous', 'HS_actual', 'HS_forecast',\n",
    "       'HS_previous']\n",
    "\n",
    "previous_price = ['y_previous_1min']\n",
    "\n",
    "col =  origin+diff+diff_bi\n",
    "\n",
    "X_train = df_train[col]\n",
    "y_train = df_train['y1'].values\n",
    "\n",
    "X_test = df_test[col]\n",
    "y_test = df_test['y1'].values\n",
    "\n",
    "col_scale = origin+diff#+diff_bi\n",
    "\n",
    "#数据标准化\n",
    "mean_value = df_diff[col_scale].mean()\n",
    "std_value = df_diff[col_scale].std()\n",
    "\n",
    "print(\"mean:\",list(mean_value))\n",
    "print(\"std:\",list(std_value))\n",
    "\n",
    "for i in range(0, len(col_scale)):\n",
    "    X_train[col_scale[i]] = X_train[col_scale[i]].apply(lambda x: (x - mean_value[i])/std_value[i])\n",
    "    X_test[col_scale[i]] = X_test[col_scale[i]].apply(lambda x: (x - mean_value[i])/std_value[i])\n",
    "\n",
    "#模型定义\n",
    "logreg = LogisticRegression(class_weight = 'balanced')\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "#模型测试\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "print(\"y_pred: \",y_pred)\n",
    "print(\"y_test: \",y_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)\n",
    "#print(\"y_pred_proba: \",logreg.predict_proba(X_test))\n",
    "print(\"训练数据集准确率：\",logreg.score(X_train[col],y_train))\n",
    "print(\"测试集准确率：\",logreg.score(X_test,y_test))\n",
    "\n",
    "# #单个数据测试\n",
    "# X_item = [196,175,33,3.8,3.8,3.8,0.1,0.2,0.4]\n",
    "# #X_item = [21,0,-0.1]\n",
    "# X_item = [1,1,0]\n",
    "# #X_item = [21,0,-0.1,1,1,0]\n",
    "# X_item = [21,0,-0.1,163,0,-0.3]\n",
    "\n",
    "\n",
    "# print(\"signal: \",logreg.predict([X_item]))\n",
    "\n",
    "#查看结果分类\n",
    "X_train_group = X_train\n",
    "X_train_group['y1'] = df_diff['y1']\n",
    "X_train_group['y_pred'] = y_pred_train\n",
    "X_train_group = X_train.groupby(['NF_diff_bi','UR_diff_bi','HS_diff_bi','y1','y_pred'])\n",
    "\n",
    "X_test_group = X_test\n",
    "X_test_group['y1'] = df_diff['y1']\n",
    "X_test_group['y_pred'] = y_pred\n",
    "X_test_group = X_test.groupby(['NF_diff_bi','UR_diff_bi','HS_diff_bi','y1','y_pred'])\n",
    "\n",
    "pd.set_option('max_row',1000) \n",
    "pd.set_option('max_columns',1000) \n",
    "\n",
    "print(pd.DataFrame(X_train_group.size()))\n",
    "print(pd.DataFrame(X_test_group.size()))\n",
    "\n",
    "print(metrics.roc_auc_score(y_test, y_pred_proba[:,1]))\n",
    "\n",
    "print(\"coef:\",logreg.coef_)\n",
    "print(\"intercept:\",logreg.intercept_)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def draw_ROC_curve(y_test,y_predict):\n",
    "    '''\n",
    "    画ROC曲线\n",
    "    '''\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test, y_predict)\n",
    "    roc_auc=auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('ROC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate,'b',label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.close(0)\n",
    "\n",
    "draw_ROC_curve(y_test, y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对结果存疑的部分，可以查看具体的源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date             time direction    turn  NF_actual  NF_forecast  \\\n",
      "3    2012/8/3   2012/8/3 20:30      Long   800.8        163          100   \n",
      "21   2016/1/8   2016/1/8 21:30     Short  2800.8        292          200   \n",
      "23   2016/3/4   2016/3/4 21:30     Short  4600.6        242          190   \n",
      "26   2016/7/8   2016/7/8 20:30     Short  4100.1        287          175   \n",
      "33   2017/2/3   2017/2/3 21:30     Short  2700.7        227          175   \n",
      "37   2017/7/7   2017/7/7 20:30     Short  4000.0        222          179   \n",
      "42  2017/12/8  2017/12/8 21:30      Long  4600.6        228          200   \n",
      "45   2018/3/9   2018/3/9 21:30      Long  3900.9        313          200   \n",
      "49   2018/7/6   2018/7/6 20:30      Long  2900.9        213          200   \n",
      "56   2019/2/1   2019/2/1 13:30       NaN     NaN        311          165   \n",
      "58   2019/4/5   2019/4/5 12:30       NaN     NaN        196          175   \n",
      "\n",
      "    previous  UR_actual  UR_forecast  UR_previous  HS_actual  HS_forecast  \\\n",
      "3         64        8.3          8.2          8.2        0.1          0.2   \n",
      "21       252        5.0          5.0          5.0        0.0          0.2   \n",
      "23       172        4.9          4.9          4.9       -0.1          0.2   \n",
      "26        11        4.9          4.8          4.7        0.1          0.2   \n",
      "33       157        4.8          4.7          4.7        0.1          0.3   \n",
      "37       152        4.4          4.3          4.3        0.2          0.3   \n",
      "42       244        4.1          4.1          4.1        0.2          0.3   \n",
      "45       239        4.1          4.0          4.1        0.1          0.2   \n",
      "49       244        4.0          3.8          3.8        0.2          0.3   \n",
      "56       222        4.0          3.9          3.9        0.1          0.3   \n",
      "58        33        3.8          3.8          3.8        0.1          0.2   \n",
      "\n",
      "    HS_previous  year  y1  NF_diff  UR_diff  HS_diff  NF_diff_AP  UR_diff_AP  \\\n",
      "3           0.3  2012  -1       63      0.1     -0.1          99         0.1   \n",
      "21          0.2  2016  -1       92      0.0     -0.2          40         0.0   \n",
      "23          0.5  2016  -1       52      0.0     -0.3          70         0.0   \n",
      "26          0.2  2016  -1      112      0.1     -0.1         276         0.2   \n",
      "33          0.2  2017  -1       52      0.1     -0.2          70         0.1   \n",
      "37          0.1  2017  -1       43      0.1     -0.1          70         0.1   \n",
      "42         -0.1  2017   1       28      0.0     -0.1         -16         0.0   \n",
      "45          0.3  2018   1      113      0.1     -0.1          74         0.0   \n",
      "49          0.3  2018   1       13      0.2     -0.1         -31         0.2   \n",
      "56          0.4  2019  -1      146      0.1     -0.2          89         0.1   \n",
      "58          0.4  2019   1       21      0.0     -0.1         163         0.0   \n",
      "\n",
      "    HS_diff_AP  NF_diff_FP  UR_diff_FP  HS_diff_FP  NF_diff_bi  UR_diff_bi  \\\n",
      "3         -0.2          36         0.0        -0.1           1         1.0   \n",
      "21        -0.2         -52         0.0         0.0           1         1.0   \n",
      "23        -0.6          18         0.0        -0.3           1         1.0   \n",
      "26        -0.1         164         0.1         0.0           1         1.0   \n",
      "33        -0.1          18         0.0         0.1           1         1.0   \n",
      "37         0.1          27         0.0         0.2           1         1.0   \n",
      "42         0.3         -44         0.0         0.4           1         1.0   \n",
      "45        -0.2         -39        -0.1        -0.1           1         1.0   \n",
      "49        -0.1         -44         0.0         0.0           1         1.0   \n",
      "56        -0.3         -57         0.0        -0.1           1         1.0   \n",
      "58        -0.3         142         0.0        -0.2           1         1.0   \n",
      "\n",
      "    HS_diff_bi  \n",
      "3          0.0  \n",
      "21         0.0  \n",
      "23         0.0  \n",
      "26         0.0  \n",
      "33         0.0  \n",
      "37         0.0  \n",
      "42         0.0  \n",
      "45         0.0  \n",
      "49         0.0  \n",
      "56         0.0  \n",
      "58         0.0  \n",
      "                                     0\n",
      "NF_diff_bi UR_diff_bi HS_diff_bi y1   \n",
      "0          0.0        0.0         1  5\n",
      "                      1.0         1  8\n",
      "           1.0        0.0         1  6\n",
      "                      1.0        -1  1\n",
      "                                  1  9\n",
      "1          0.0        0.0        -1  3\n",
      "                                  1  1\n",
      "                      1.0        -1  4\n",
      "                                  1  2\n",
      "           1.0        0.0        -1  7\n",
      "                                  1  4\n",
      "                      1.0        -1  9\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(df_diff[(df_diff.NF_diff_bi == 1)&(df_diff.UR_diff_bi == 1)&(df_diff.HS_diff_bi == 0)]))\n",
    "\n",
    "df_diff_group = df_diff.groupby(['NF_diff_bi','UR_diff_bi','HS_diff_bi','y1'])\n",
    "print(pd.DataFrame(df_diff_group.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将上上个格子输出的四个参数复制到下面的函数，就可以直接用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是1的概率： [0.09170159]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "def NF_score(input,threshold = 0.5):\n",
    "    bi = preprocessing.Binarizer(copy=True, threshold=-0.000001)\n",
    "    \n",
    "    coef = [-1.03448822,  0.23754841, -0.2418439 ,  0.12376236,  0.15298568,\n",
    "        0.14432753, -0.32862321, -0.72987482, -0.69119416, -1.2934256 ,\n",
    "       -0.3320293 , -0.10901835, -0.52836275, -0.21826463,  0.19434201,\n",
    "        0.35576964,  0.20461333,  0.39568772, -1.0742329 ,  0.36672291,\n",
    "       -0.13393514]\n",
    "    intercept = [0.39621412]\n",
    "    \n",
    "    mean = [193.79661016949152, 191.0, 195.0, 4.967796610169491, 4.996610169491524, 5.022033898305083, 0.19661016949152546, 0.23559322033898317, 0.20677966101694917, 2.7966101694915255, -0.028813559322033857, -0.03898305084745764, -1.2033898305084745, -0.05423728813559318, -0.010169491525423726, -4.0, -0.025423728813559324, 0.028813559322033895]\n",
    "    std = [72.19174173351011, 34.36116492746446, 76.02789869061452, 1.1652202215958565, 1.1976940634193571, 1.1923705447856685, 0.15082085936280926, 0.04829047119687413, 0.14247129992855187, 64.0500288462658, 0.11751866683363194, 0.13132868630160083, 106.54540551608403, 0.12774170314957245, 0.25168050028875716, 74.6250397100339, 0.05443509371017502, 0.15979604183267077]\n",
    "    \n",
    "    NF_diff_AF = input[0] - input[1]\n",
    "    UR_diff_AF = input[3] - input[4]\n",
    "    HS_diff_AF = input[6] - input[7]\n",
    "    NF_diff_AP = input[0] - input[2]\n",
    "    UR_diff_AP = input[3] - input[5]\n",
    "    HS_diff_AP = input[6] - input[8]\n",
    "    NF_diff_FP = input[1] - input[2]\n",
    "    UR_diff_FP = input[4] - input[5]\n",
    "    HS_diff_FP = input[7] - input[8]\n",
    "    \n",
    "    diff = input + [NF_diff_AF,UR_diff_AF,HS_diff_AF,\n",
    "            NF_diff_AP,UR_diff_AP,HS_diff_AP,\n",
    "            NF_diff_FP,UR_diff_FP,HS_diff_FP]\n",
    "    \n",
    "    for i in range(0,len(diff)):\n",
    "        diff[i] = (diff[i] - mean_value[i])/std_value[i]\n",
    "    \n",
    "    NF_diff_AF_bi = bi.transform(NF_diff_AF)\n",
    "    UR_diff_AF_bi = bi.transform(UR_diff_AF)\n",
    "    HS_diff_AF_bi = bi.transform(HS_diff_AF)\n",
    "    \n",
    "    data = diff + [NF_diff_AF_bi,UR_diff_AF_bi,HS_diff_AF_bi]\n",
    "    \n",
    "    result = 1/(1 + np.exp(-(np.dot(data, np.array(coef).T))) + intercept)\n",
    "    print(\"是1的概率：\",result)\n",
    "    \n",
    "    return (1 if result>=threshold else 0)\n",
    "\n",
    "\n",
    "X_item = [196,175,33,3.8,3.8,3.8,0.1,0.2,0.4]\n",
    "threshold = 0.5\n",
    "\n",
    "print(NF_score(X_item,threshold))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
